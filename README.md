# Machine Learning 1 Labs

This repository contains Labs from the Machine Learning 1 course in September-October 2019 at the University of Amsterdam Master AI.

## Lab 1: Regression: Linear Regression and Bayesian Linear Regression

The topic of lab 1 is Linear Regression and Overfitting. Part 1 covers Polynomial Regression and Model selection with Cross-validation. In Part 2, a Bayesian Linear Regression model is implemented and fitted to periodic data, after which the Predictive distribution is derived and plotted.

Packages used for this assignment include `numpy`, `scipy`, and `matplotlib` for plotting.

## Lab 2: Classification: Logistic Regression and Multi-layer Perceptron

Lab 2 is about Classification and covers logistic regression and multilayer perceptrons. 

The lab assignment starts with implementing multiclass logistic regression in Part 1 for the MNIST dataset. Gradient equations for Gradient-based stochastic optimization are derived; using these equations the gradient computations and stochastic gradient descent (SGD) are implemented. What follows is the training of the logistic regression model, visualising the weights and analysing the results.

In part 2, the same problem is tackled using a multilayer perceptron (MLP). Gradient equations for maximum likelihood are derived and the MLP is subsequently implemented. Different activation functions are also studied.

## Lab 3: Gaussian Processes and Support Vector Machines

The topic of lab 3 is Gaussian Processes (GPs) and Support Vector Machines (SVMs).

Part 1 covers the importance of kernel functions, sampling from the Gaussian process prior, plotting function samples and implement the predictive distribution. Part 2 covers Support Vector machines and plotting support vectors and decision boundaries.
